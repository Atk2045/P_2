{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+j3YgHDJu78eGES20kusy"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4xHHREfpN6R",
        "outputId": "47d22593-017d-4119-fd8c-d6013595ca5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to squad debriefer\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import re\n",
        "\n",
        "# Fundamental BeautifulSoup scraper as in the video recording\n",
        "\n",
        "# Error handeling ( try - except) for incorrect URL to check if there's an error from the beginning of the code\n",
        "def scrape_the_data(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.encoding = 'utf-8'\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        return soup\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error fetching {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Main function 1 - getting the team roaster from fbref website to be accessible for the user\n",
        "def squad_details(url):\n",
        "\n",
        "    import json\n",
        "\n",
        "    soup = scrape_the_data(url)\n",
        "    #Finding the tbody that contains the player data\n",
        "    tbody = soup.find('tbody')\n",
        "    # Checking if the tbody exists\n",
        "    if tbody:\n",
        "      # Extracting all rows <tr> within the tbody\n",
        "      rows = tbody.find_all('tr')\n",
        "    else:\n",
        "      # If no tbody is found, try finding rows directly inside the table\n",
        "      rows = soup2.find_all('tr')\n",
        "\n",
        "    global team_dict\n",
        "\n",
        "# creating a dictionary with sub-dictionaries for every position\n",
        "\n",
        "    team_dict = {\n",
        "      'Goalkeepers': {},\n",
        "      'Defenders': {},\n",
        "      'Midfielders': {},\n",
        "      'Forwards': {}\n",
        "      }\n",
        "\n",
        "    for row in rows:\n",
        "      # Extract player data by position\n",
        "\n",
        "      if row:\n",
        "        player_name = row.find('th', {'data-stat': 'player'}).get_text(strip=True)\n",
        "        player_position = row.find('td', {'data-stat': 'position'}).get_text(strip=True)\n",
        "        player_ID = row.find('th', {'data-append-csv': True})['data-append-csv']\n",
        "\n",
        "        # Assigning players to their positions according to the website for clarity and organization\n",
        "        # players are assigned to Goalkeepers/ Defenders/ Midfielders/ Forwards\n",
        "        if 'GK' in player_position:\n",
        "            team_dict['Goalkeepers'][player_ID] = {\n",
        "                'Player_name': player_name,\n",
        "                'Player_position': player_position\n",
        "            }\n",
        "        elif 'DF' in player_position:\n",
        "            team_dict['Defenders'][player_ID] = {\n",
        "                'Player_name': player_name,\n",
        "                'Player_position': player_position\n",
        "            }\n",
        "        elif 'MF' in player_position:\n",
        "            team_dict['Midfielders'][player_ID] = {\n",
        "                'Player_name': player_name,\n",
        "                'Player_position': player_position\n",
        "            }\n",
        "        elif 'FW' in player_position:\n",
        "            team_dict['Forwards'][player_ID] = {\n",
        "                'Player_name': player_name,\n",
        "                'Player_position': player_position\n",
        "            }\n",
        "\n",
        "    # Print the final dict with all positions and all players\n",
        "\n",
        "    for positions, players in team_dict.items():\n",
        "        print(positions + ':')\n",
        "        print(json.dumps(players, indent=4, ensure_ascii=False))\n",
        "        print()\n",
        "\n",
        "# Main function 2 - Printing player stats for the user\n",
        "\n",
        "def player_stats(url):\n",
        "    soup = scrape_the_data(url)\n",
        "\n",
        "    # Find the div with id that starts with \"div_scout_summary\" table which contains the summary\n",
        "    div = soup.find('div', id=lambda x: x and x.startswith('div_scout_summary'))\n",
        "\n",
        "    # checking if div exists to get the stats\n",
        "    if div:\n",
        "      div_id = div.get('id')\n",
        "      result = div_id.replace('div_', '')\n",
        "\n",
        "      specific_table = soup.find('table', id= result)\n",
        "\n",
        "    if specific_table:\n",
        "      rows = specific_table.find_all('tr')\n",
        "\n",
        "    for row in rows:\n",
        "        #this for loop there is a <th> tag and it contains text\n",
        "        stat_name_tag = row.find('th')\n",
        "        stat_name = stat_name_tag.text.strip()\n",
        "\n",
        "        # Find all <td> elements in the code\n",
        "        td_tags = row.find_all('td')\n",
        "        # ensure there are at least two\n",
        "        if len(td_tags) >= 2:\n",
        "            # Check if there's a div in the second <td> element\n",
        "            div_tag = td_tags[1].find('div')\n",
        "            if div_tag:\n",
        "                percentile = div_tag.text.strip()\n",
        "                print(f\"Statistic: {stat_name}, Percentile: {percentile}\")\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "# getting the ID from dictionary created\n",
        "def get_player_id(dictionary, name):\n",
        "    for position, players in dictionary.items():\n",
        "        for player_id, info in players.items():\n",
        "            if info.get(\"Player_name\") == name:\n",
        "                return player_id, info[\"Player_name\"]\n",
        "                # this returns none if there's no id match found\n",
        "    return None, None\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"Welcome to squad debriefer\")\n",
        "    URL = input(\"Please input the team URL:  \")\n",
        "\n",
        "    # REGEX was used here\n",
        "    pattern = r'/squads/\\w+/([^/]+)'\n",
        "    raw_name = re.search(pattern, URL)\n",
        "    team_name = raw_name.group(1)\n",
        "    team_name = team_name.replace('-Stats','')\n",
        "\n",
        "    print(f\"{team_name} squad details: \")\n",
        "    squad_details(URL)\n",
        "\n",
        "# Flags for errors and terminating the program\n",
        "\n",
        "    flag = True\n",
        "\n",
        "\n",
        "# while looop for starting the program when Flag is true\n",
        "\n",
        "    while (flag):\n",
        "        print(\"which player would you like to investigate?\")\n",
        "        name = input(\"Please copy and paste the name from dictionary:  \")\n",
        "\n",
        "        #player_id, player_name = get_player_id(team_dict, name)\n",
        "        #player_name_insert = player_name.replace(\" \",\"-\")\n",
        "\n",
        "        name_flag = True\n",
        "\n",
        "        while name_flag:\n",
        "            player_id, player_name = get_player_id(team_dict, name)\n",
        "            if player_name:\n",
        "                player_name_insert = player_name.replace(\" \", \"-\")\n",
        "                name_flag = False\n",
        "            else:\n",
        "                print('Error detected. Please provide a proper name from the dictionary.')\n",
        "                name = input(\"Please copy and paste the name from the dictionary: \")\n",
        "\n",
        "        name_url = \"https://fbref.com/en/players/\"+player_id+\"/\"+player_name_insert\n",
        "        print()\n",
        "        player_stats(name_url)\n",
        "\n",
        "\n",
        "# while loop for continuation of the program after getting the first summary stats\n",
        "\n",
        "        while True:\n",
        "            response = input(\"Continue? (Y/N): \")\n",
        "            if response == \"Y\":\n",
        "                break\n",
        "            elif response == \"N\":\n",
        "                flag = False\n",
        "                break\n",
        "            else:\n",
        "                print(\"Please respond with Y or N\")\n",
        "\n",
        "\n",
        "main()\n",
        "\n",
        "# we used GPT for starting point on Beautifulsoup functions (ex. request, .find, .findall) and certain complex operations (ex. ascii=false, Json dump, dictionary setting, regex)\n",
        "#However, all code structure and functionalitties have been thought of and implemented by us\n",
        "\n"
      ]
    }
  ]
}